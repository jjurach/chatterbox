# Task 4.7: Integrate LLM with System Prompts

**Status:** Completed
**Date:** 2026-02-20
**Epic:** Epic 4 — LLM Integration with Tool Calling

---

## Summary

Completed LLM provider integration with error handling, rate limiting, and cost
tracking. The core LLM integration (tool definition passing, response parsing,
system prompt, tool-calling loop) was already implemented in Tasks 4.2–4.6.
This task adds the operational hardening layer: typed API error hierarchy,
client-side rate limiting, per-call token usage and cost tracking, and
propagation of LLM-specific errors to `ChatterboxConversationEntity` with
user-friendly spoken responses.

## Changes

### `src/chatterbox/conversation/providers.py`

**New: Exception hierarchy**

- `LLMError` — base exception for all LLM provider errors.
- `LLMRateLimitError(LLMError)` — raised on 429 rate-limit responses.
- `LLMConnectionError(LLMError)` — raised when the API endpoint is unreachable.
- `LLMAPIError(LLMError)` — raised for other API failures; exposes `status_code`.

**New: `UsageStats` dataclass**

Fields: `prompt_tokens`, `completion_tokens`, `total_tokens`,
`estimated_cost_usd: float | None`.

**New: `CostEstimator` class**

`estimate(model, prompt_tokens, completion_tokens) -> float | None`.
Built-in cost database covers GPT-4o, GPT-4o-mini, GPT-4-turbo, GPT-4,
GPT-3.5-turbo, and Claude (Haiku/Sonnet/Opus 4.x). Returns `None` for
unknown models rather than raising.

**New: `RateLimiter` class**

`RateLimiter(calls_per_minute: int)` — async sliding-window rate limiter.
`await rate_limiter.acquire()` sleeps until a call slot is available.
Raises `ValueError` for non-positive `calls_per_minute`.

**Updated: `CompletionResult`**

Added optional `usage: UsageStats | None = None` field.

**Updated: `OpenAICompatibleProvider`**

- New constructor parameters: `rate_limiter: RateLimiter | None = None`,
  `cost_estimator: CostEstimator | None = None`.
- `complete()` now:
  - Calls `await self.rate_limiter.acquire()` before each request (if set).
  - Catches `openai.RateLimitError` → `LLMRateLimitError`.
  - Catches `openai.APIConnectionError` → `LLMConnectionError`.
  - Catches `openai.APIStatusError` → `LLMAPIError` (with `status_code`).
  - Populates `CompletionResult.usage` from `response.usage` when present.
  - Uses `CostEstimator` if provided to compute `estimated_cost_usd`.

### `src/chatterbox/conversation/entity.py`

**Updated: `ChatterboxConversationEntity.async_process()`**

Added specific `except` blocks for:
- `LLMRateLimitError` → "I'm sorry, I'm receiving too many requests right now."
- `LLMConnectionError` → "I'm sorry, I can't reach my language model right now."
- `LLMAPIError` → "I'm sorry, my language model returned an error."

All error paths echo `conversation_id` and do not pollute session history
(same guarantee as the existing `RuntimeError` handler).

### `tests/unit/test_conversation/test_providers.py`

Added 25 new tests covering:
- Exception hierarchy (5 tests).
- `UsageStats` dataclass (2 tests).
- `CostEstimator` (5 tests: known GPT-4o, GPT-4o-mini, unknown model, zero tokens, Claude).
- `RateLimiter` (5 tests: invalid config, stores config, calls within limit, timestamp recording).
- `CompletionResult.usage` field (2 tests).
- `OpenAICompatibleProvider` API error handling (3 tests: 429, connection error, 5xx).
- `OpenAICompatibleProvider` rate limiter integration (1 test).
- `OpenAICompatibleProvider` cost tracking (2 tests).

### `tests/unit/test_conversation/test_entity.py`

Added 5 new tests covering:
- `LLMRateLimitError` → graceful error response.
- `LLMConnectionError` → graceful error response.
- `LLMAPIError` → graceful error response.
- Rate-limit error echoes `conversation_id`.
- Connection error does not pollute session history.

## Verification Results

```
Command: /home/phaedrus/hentown/modules/chatterbox/venv/bin/pytest tests/unit/ -q

Result:
177 passed, 3 warnings in 2.30s
```

No regressions. Test count increased from 147 → 177 (+30 new tests in Task 4.7).

### Test breakdown (conversation package)

```
tests/unit/test_conversation/test_entity.py     18 tests  (was 13)
tests/unit/test_conversation/test_loop.py       14 tests
tests/unit/test_conversation/test_providers.py  32 tests  (was 7)
tests/unit/test_conversation/test_tools/       68 tests
```

## Design Notes

- **Rate limiting** — The `RateLimiter` is client-side only (sliding window). It
  complements the server's built-in retries; it does not replace them. The
  OpenAI SDK already retries on 429 by default.

- **Cost tracking** — The `CostEstimator` database uses approximate published
  prices. Actual billing may differ. For cost-sensitive production use, query
  the API's billing endpoint directly.

- **Backward compatibility** — `CompletionResult.usage` defaults to `None`; all
  existing callers that don't inspect `usage` are unaffected. The new
  `OpenAICompatibleProvider` parameters are optional with `None` defaults.

## Known Issues

- None. The `RateLimiter` does not yet have configurable per-second limits
  (only per-minute). If sub-minute burst control is needed, a token-bucket
  variant could be added in a future task.
